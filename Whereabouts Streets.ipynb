{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Whereabout Streets Data Extraction\n",
    "This notebook will demonstrate how to access Street and Bridge Operations PDF file and extract this data to create a work order plan template.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://upload.wikimedia.org/wikipedia/en/9/94/Closeup_of_pavement_with_grass.JPG\" /></div>\n",
    "\n",
    "## Introduction\n",
    "The purpose of this notebook is to create a Street and Bridge Work Order plans based on segment IDs and additional comments on long line. Markings feature layers are published in the City of Austin ArcGIS Portal page available for public view as well. \n",
    "\n",
    "The schedule for where sealcoat and overlay streets are completed is received through email by Street and Bridge Operations on a daily basis. It is sent as a PDF file that lists weather conditions, temperature, and provides a table of streets where paving is completed.\n",
    "\n",
    "<b>The only manual process the user will have to do is to:</b>\n",
    "- Input Segment IDs\n",
    "- Make comments on long line markings\n",
    "- Specify MONTH/DAY/YEAR to retrieve the table of completed streets paved for PDF name and file path\n",
    "- Create any missing markings assets that are not visible in aerial imagery\n",
    "\n",
    "This process will cut down on the previous process of manually editing a plans layout through copy-pasting imagery and writing Location IDs, work groups, markings found, and the exporting plans one at a time. An excel document will be created based on this input and read segment IDs to find all short line and specialty point markings. This will ideally generate multiple PDF plans in a faster and shorter time frame.\n",
    "\n",
    "In the future I would like to make this script more customizable and be done seamlessly without inputting Segment IDs and inputting only specific long line markings using the maintained streets feature layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "The packages used for this project are:\n",
    "- [exchangelib](https://github.com/ecederstrand/exchangelib) to access the attachments sent by Street and Bridge Operations\n",
    "- [pdfplumber](https://github.com/jsvine/pdfplumber) to extract tables from the whereabouts report\n",
    "- [pandas](https://pandas.pydata.org/) to create dataframe of extracted table and transform the data\n",
    "- [openpyxl](https://openpyxl.readthedocs.io/en/stable/) to edit excel files\n",
    "- [arcgis](https://esri.github.io/arcgis-python-api/apidoc/html/) to search for markings feature layer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exchangelib import DELEGATE, Account, Credentials, Configuration, FileAttachment, ItemAttachment\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook,load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "The date by month and day constant will determine the file pdf name to use as a dataframe. Folder path will determine where the plans will be created depending on the year. This is set to the top for the purpose of changing these constants as needed.\n",
    "\n",
    "<i>The table below explains the purpose of each constant.</i>\n",
    "\n",
    "| Constant | Description   |\n",
    "|:--------:|----|\n",
    "| <b>MONTH, DAY, YEAR</b> |Date used to find PDF in month-day format and file path based on year|\n",
    "|<b>FOLDER</b>      |File directory used to import SBO whereabouts reports from email|\n",
    "|<b>FILE_NAME</b>   |File directory name used to extact SBO whereabouts reports from file|\n",
    "|<b>SIGN_IN</b>   |Whether to prompt user to sign in to outlook email|\n",
    "|<b>INPUT</b>|Whether to prompt user to input segment Ids and comments to export to excel| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'MONTH' (str)\n",
      "Stored 'DAY' (str)\n",
      "Stored 'YEAR' (str)\n",
      "Stored 'FOLDER' (str)\n",
      "Stored 'FILE_NAME' (str)\n"
     ]
    }
   ],
   "source": [
    "MONTH,DAY,YEAR = ('July',str(16),str(2019))\n",
    "FOLDER = (r\"G:\\ATD\\Signs_and_Markings\\MARKINGS\\Whereabouts WORK ORDERS\\{}\\Whereabouts_Summary\").format(YEAR)\n",
    "FILE_NAME = \"\\\\\".join((FOLDER,\" \".join((MONTH,DAY))))\n",
    "SIGN_IN = False\n",
    "INPUT= True\n",
    "\n",
    "%store MONTH\n",
    "%store DAY\n",
    "%store YEAR\n",
    "%store FOLDER\n",
    "%store FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "These functions will be used to extract and transform the data into a feasible format.\n",
    "\n",
    "<i>The table below explains the purpose of each:</i>\n",
    "\n",
    "| Method | Description   |\n",
    "|:--------:|----|\n",
    "|<b>lists_to_df</b> |Converts extracted nested list into a dataframe|\n",
    "|<b>pdf_table_to_df</b> |Extracts table from PDF and then converts to dataframe|\n",
    "|<b>input_form</b> |Prompts user to input segment IDs and long line specifications|\n",
    "|<b>query_df</b>   |Query dataframe by segment IDs|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns dataframe of transformed extracted table\n",
    "def lists_to_df(data,columns):\n",
    "    l = [item for sublist in data for item in sublist]\n",
    "    l = [[ x for x in y if x != None and x != ''] for y in l] \n",
    "    l = [x for x in l if x[0] != 'ID#']\n",
    "    for i in l:\n",
    "        if i[0].isdigit() == False:\n",
    "            del i[0]\n",
    "        del i[len(columns):len(i)]\n",
    "    df = pd.DataFrame(l,columns=columns)\n",
    "    return df\n",
    "\n",
    "# Opens PDF to extract table and convert to dataframe\n",
    "def pdf_table_to_df(columns):\n",
    "    with pdfplumber.open(FILE_NAME + \".pdf\") as pdf:\n",
    "        pg1 = pdf.pages[0]\n",
    "        data = pg1.extract_tables(table_settings={})\n",
    "        df = lists_to_df(data,columns)\n",
    "        pdf.close()\n",
    "        return df\n",
    "\n",
    "# Prompts user to input segment IDs and comments while changing the datafram to include user input\n",
    "def input_form(df,columns):\n",
    "    segments, comments = [],[]\n",
    "    for index,row in df.iterrows():\n",
    "        location = \"{} from {} to {}\".format(row[\"Street\"],row[\"From\"],row[\"To\"])\n",
    "        console = input(location + \"\\nSegment ID list: \")\n",
    "        try:\n",
    "            list_s = list(map(int, console.split('\\t')))\n",
    "            segments.append(console)\n",
    "        except ValueError:\n",
    "            print(\"Skipping input...\")\n",
    "            segments.append(None)\n",
    "        comment = input(\"Comment: \")\n",
    "        comments.append(comment)\n",
    "    df['Segment IDs'], df['Comments'] = ([s.replace('\\t',',') if s != None else None for s in segments ],comments)\n",
    "    print(\"\\nInput complete.\")\n",
    "    \n",
    "# Returns query dataframe appended if markings exist in the listed segment IDs\n",
    "def query_df(fc,index,f,df,df1):\n",
    "    q = \"SEGMENT_ID IN({})\".format(df[\"Segment IDs\"][index])\n",
    "    if q != \"SEGMENT_ID IN(None)\":\n",
    "        c = fc.query(where=q,return_count_only=True) \n",
    "        if c != 0:\n",
    "            sdf = fc.query(where=q).sdf.filter(items=f)\n",
    "            sdf[\"Location ID\"] = df[\"Location ID\"][index]\n",
    "            sdf[\"Comments\"]= df[\"Comments\"][index]\n",
    "            df1 = df1.append(sdf)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Loading and Transforming Data\n",
    "\n",
    "### Email Attachment Extraction\n",
    "\n",
    "Attachments will be extracted from the inbox. The purpose of `getpass` is to prompt the user for a password to login to email. \n",
    "\n",
    "Since the attachments have already been exported to the directory file, a sign-in is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Email subject line used for Street and Bridge Whereabouts report\n",
    "daily_subject = \"S&B Whereabouts\"\n",
    "\n",
    "# This will try to prompt the user to input email and password if SIGN_IN is True\n",
    "try:\n",
    "    if SIGN_IN:\n",
    "        email = input(\"Enter email: \")\n",
    "        password = getpass.getpass(\"Enter password: \")\n",
    "        credentials = Credentials(username = email,password = password)\n",
    "        config = Configuration(server='outlook.office365.com', credentials=credentials)\n",
    "        account = Account(\n",
    "            primary_smtp_address=email,\n",
    "            config=config,\n",
    "            autodiscover=False,\n",
    "            access_type=DELEGATE)\n",
    "        print(\"\\nFile attachments below are:\")\n",
    "        for item in account.inbox.filter(subject__contains=daily_subject):\n",
    "            for attachment in item.attachments:\n",
    "                if isinstance(attachment, FileAttachment):\n",
    "                    file_path = \"\\\\\".join([FOLDER,attachment.name])\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(attachment.content)\n",
    "                    print(file_path)\n",
    "except:\n",
    "    print(\"\\nWrong username or password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF tables to Excel\n",
    "\n",
    "Now that the PDFs have been extracted and exported to the folder path, the next step is to extract the tables in the PDF and export it as an excel file.\n",
    "\n",
    "An input form will generate so the user can input Segment ID and comment information for each of the streets listed. The columns list will only take the relevant columns from the extracted table. The `pdfplumber` package will be used to extract tables from the PDF and prompt user to submit data.\n",
    "\n",
    "The input will be stored as a DataFrame saved to an excel document. If the user already provided input froma  previous session, the dataframe will be set to the excel file document instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "MEADOWBROOK DR  day 2 from Windsor Rd to Bridle Path\n",
      "Segment ID list:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping input...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Comment:  \n",
      "TRINITY HILL DR from Plaza Dr to Riddlewood Dr\n",
      "Segment ID list:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping input...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Comment:  \n",
      "RIDDLEWOOD DR from Spring Hill Dr to Trinity Hill Dr\n",
      "Segment ID list:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping input...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Comment:  \n",
      "RIVER OAKS DR from Dove Haven Dr to River Oaks Trl\n",
      "Segment ID list:  2009930\t2009952\t2039520\n",
      "Comment:  \n",
      "RIVER OAKS TRL from Spring Hill Dr to River Oaks Dr\n",
      "Segment ID list:  2038097\t2010132\t2010095\t2010101\t2010027\t2010061\t2039586\t2009974\n",
      "Comment:  \n",
      "BERRYWOOD DR from Oak Haven Cv to River Oaks Trl\n",
      "Segment ID list:  2010019\t2010105\t2010092\t2010106\t2010040\n",
      "Comment:  \n",
      "SPRINGHILL DR from Dead End to River Oaks Trl\n",
      "Segment ID list:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping input...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Comment:  \n",
      "HORACE DR from Newport Ave to Applegate Dr E\n",
      "Segment ID list:  2012499\n",
      "Comment:  \n",
      "SOMERSET AVE from Applegate Dr E to Applegate Dr E\n",
      "Segment ID list:  2039864\n",
      "Comment:  \n",
      "APPLEGATE DR E from Walnut Bend Dr to Somerset Ave\n",
      "Segment ID list:  2010619\t2039876\t2039869\n",
      "Comment:  \n",
      "SALEM LN from Middle Fiskville Rd to Walnut Bend Dr\n",
      "Segment ID list:  2010599\t2010624\n",
      "Comment:  \n",
      "FLORADALE DR from Middle Fiskville Rd to Cy Ln\n",
      "Segment ID list:  2010714\t2010663\n",
      "Comment:  \n",
      "RUBY DR from I 35 Svc Rd Nb N to Joseph Clayton Dr\n",
      "Segment ID list:  2039714\n",
      "Comment:  \n",
      "DENELL CIR from Walnut Bend Dr to 10638\n",
      "Segment ID list:  2039819\n",
      "Comment:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Columns of extracted table\n",
    "columns = [\"Location ID\", \"Street\", \"From\", \"To\"]\n",
    "excel_file = FILE_NAME + \".xlsx\"\n",
    "        \n",
    "# Will prompt input and export to excel unless the excel file already exists. In that case it will read excel file instead\n",
    "if Path(excel_file).exists():\n",
    "    df = pd.read_excel(excel_file,index_col=0)\n",
    "else:\n",
    "    if INPUT:\n",
    "        df = pdf_table_to_df(columns)\n",
    "        input_form(df,columns)\n",
    "        df.to_excel(excel_file,sheet_name=\" \".join((MONTH,DAY)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Segment IDs</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74354</td>\n",
       "      <td>MEADOWBROOK DR  day 2</td>\n",
       "      <td>Windsor Rd</td>\n",
       "      <td>Bridle Path</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63218</td>\n",
       "      <td>TRINITY HILL DR</td>\n",
       "      <td>Plaza Dr</td>\n",
       "      <td>Riddlewood Dr</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63132</td>\n",
       "      <td>RIDDLEWOOD DR</td>\n",
       "      <td>Spring Hill Dr</td>\n",
       "      <td>Trinity Hill Dr</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63135</td>\n",
       "      <td>RIVER OAKS DR</td>\n",
       "      <td>Dove Haven Dr</td>\n",
       "      <td>River Oaks Trl</td>\n",
       "      <td>2009930,2009952,2039520</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63136</td>\n",
       "      <td>RIVER OAKS TRL</td>\n",
       "      <td>Spring Hill Dr</td>\n",
       "      <td>River Oaks Dr</td>\n",
       "      <td>2038097,2010132,2010095,2010101,2010027,201006...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62792</td>\n",
       "      <td>BERRYWOOD DR</td>\n",
       "      <td>Oak Haven Cv</td>\n",
       "      <td>River Oaks Trl</td>\n",
       "      <td>2010019,2010105,2010092,2010106,2010040</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63180</td>\n",
       "      <td>SPRINGHILL DR</td>\n",
       "      <td>Dead End</td>\n",
       "      <td>River Oaks Trl</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62958</td>\n",
       "      <td>HORACE DR</td>\n",
       "      <td>Newport Ave</td>\n",
       "      <td>Applegate Dr E</td>\n",
       "      <td>2012499</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63177</td>\n",
       "      <td>SOMERSET AVE</td>\n",
       "      <td>Applegate Dr E</td>\n",
       "      <td>Applegate Dr E</td>\n",
       "      <td>2039864</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62749</td>\n",
       "      <td>APPLEGATE DR E</td>\n",
       "      <td>Walnut Bend Dr</td>\n",
       "      <td>Somerset Ave</td>\n",
       "      <td>2010619,2039876,2039869</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63151</td>\n",
       "      <td>SALEM LN</td>\n",
       "      <td>Middle Fiskville Rd</td>\n",
       "      <td>Walnut Bend Dr</td>\n",
       "      <td>2010599,2010624</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62907</td>\n",
       "      <td>FLORADALE DR</td>\n",
       "      <td>Middle Fiskville Rd</td>\n",
       "      <td>Cy Ln</td>\n",
       "      <td>2010714,2010663</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63148</td>\n",
       "      <td>RUBY DR</td>\n",
       "      <td>I 35 Svc Rd Nb N</td>\n",
       "      <td>Joseph Clayton Dr</td>\n",
       "      <td>2039714</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62874</td>\n",
       "      <td>DENELL CIR</td>\n",
       "      <td>Walnut Bend Dr</td>\n",
       "      <td>10638</td>\n",
       "      <td>2039819</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location ID                 Street                 From                 To  \\\n",
       "0        74354  MEADOWBROOK DR  day 2           Windsor Rd        Bridle Path   \n",
       "1        63218        TRINITY HILL DR             Plaza Dr      Riddlewood Dr   \n",
       "2        63132          RIDDLEWOOD DR       Spring Hill Dr    Trinity Hill Dr   \n",
       "3        63135          RIVER OAKS DR        Dove Haven Dr     River Oaks Trl   \n",
       "4        63136         RIVER OAKS TRL       Spring Hill Dr      River Oaks Dr   \n",
       "5        62792           BERRYWOOD DR         Oak Haven Cv     River Oaks Trl   \n",
       "6        63180          SPRINGHILL DR             Dead End     River Oaks Trl   \n",
       "7        62958              HORACE DR          Newport Ave     Applegate Dr E   \n",
       "8        63177           SOMERSET AVE       Applegate Dr E     Applegate Dr E   \n",
       "9        62749         APPLEGATE DR E       Walnut Bend Dr       Somerset Ave   \n",
       "10       63151               SALEM LN  Middle Fiskville Rd     Walnut Bend Dr   \n",
       "11       62907           FLORADALE DR  Middle Fiskville Rd              Cy Ln   \n",
       "12       63148                RUBY DR     I 35 Svc Rd Nb N  Joseph Clayton Dr   \n",
       "13       62874             DENELL CIR       Walnut Bend Dr              10638   \n",
       "\n",
       "                                          Segment IDs Comments  \n",
       "0                                                 N/A           \n",
       "1                                                 N/A           \n",
       "2                                                 N/A           \n",
       "3                             2009930,2009952,2039520           \n",
       "4   2038097,2010132,2010095,2010101,2010027,201006...           \n",
       "5             2010019,2010105,2010092,2010106,2010040           \n",
       "6                                                 N/A           \n",
       "7                                             2012499           \n",
       "8                                             2039864           \n",
       "9                             2010619,2039876,2039869           \n",
       "10                                    2010599,2010624           \n",
       "11                                    2010714,2010663           \n",
       "12                                            2039714           \n",
       "13                                            2039819           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.fillna(\"N/A\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a table for the list of streets with the following columns:\n",
    "- <i>Location ID</i>: unique identifier used for street paving\n",
    "- <i>Street</i>: main street that is paved\n",
    "- <i>From</i>: intersecting cross street\n",
    "- <i>To</i>: intersecting cross street\n",
    "- <i>Segment IDs</i>: list of segment IDs where street is paved seperated by commas\n",
    "- <i>Comments</i>: Notes on long line markings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Layer Data Query\n",
    "\n",
    "The next task is to find the markings through the list of segment IDs the user has inputted. For this task the `arcgis` package will be useful for extracting the markings available in each segment ID since the dataset is already available publically.\n",
    "\n",
    "Since the markings datasets are publically available, we can login to ArcGIS Online anonymously. \n",
    "\n",
    "Use `client_id` instead of `None` if you wish to log-in through an AGOL federate account. Note that it will prompt user to enter code which can be found by following the instructions. Going through an AGOL federated account is useful if the user wishes to add their own layers as a reference such as [NearMap](https://go.nearmap.com/) aerial imagery. \n",
    "\n",
    "It will search through the markings feature layer based on the list of segment IDs provided by the excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION ID</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>SHORTLINE ID</th>\n",
       "      <th>SHORTLINE TYPE</th>\n",
       "      <th>SEGMENT ID</th>\n",
       "      <th>SPECIALTY ID</th>\n",
       "      <th>SPECIALTY TYPE</th>\n",
       "      <th>SPECIALTY SUBTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62958</td>\n",
       "      <td></td>\n",
       "      <td>9100</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2012499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62958</td>\n",
       "      <td></td>\n",
       "      <td>12617</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2012499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63177</td>\n",
       "      <td></td>\n",
       "      <td>9468</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2039864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63177</td>\n",
       "      <td></td>\n",
       "      <td>522</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2039864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62749</td>\n",
       "      <td></td>\n",
       "      <td>6643</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2039876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62749</td>\n",
       "      <td></td>\n",
       "      <td>9386</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2039869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62749</td>\n",
       "      <td></td>\n",
       "      <td>9387</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63151</td>\n",
       "      <td></td>\n",
       "      <td>6715</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63151</td>\n",
       "      <td></td>\n",
       "      <td>8517</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63151</td>\n",
       "      <td></td>\n",
       "      <td>9022</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62907</td>\n",
       "      <td></td>\n",
       "      <td>7472</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62907</td>\n",
       "      <td></td>\n",
       "      <td>9021</td>\n",
       "      <td>STOP_LINE</td>\n",
       "      <td>2010714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION ID COMMENTS  SHORTLINE ID SHORTLINE TYPE  SEGMENT ID  SPECIALTY ID  \\\n",
       "0       62958                   9100      STOP_LINE     2012499           NaN   \n",
       "1       62958                  12617      STOP_LINE     2012499           NaN   \n",
       "0       63177                   9468      STOP_LINE     2039864           NaN   \n",
       "1       63177                    522      STOP_LINE     2039864           NaN   \n",
       "0       62749                   6643      STOP_LINE     2039876           NaN   \n",
       "1       62749                   9386      STOP_LINE     2039869           NaN   \n",
       "2       62749                   9387      STOP_LINE     2010619           NaN   \n",
       "0       63151                   6715      STOP_LINE     2010624           NaN   \n",
       "1       63151                   8517      STOP_LINE     2010624           NaN   \n",
       "2       63151                   9022      STOP_LINE     2010599           NaN   \n",
       "0       62907                   7472      STOP_LINE     2010663           NaN   \n",
       "1       62907                   9021      STOP_LINE     2010714           NaN   \n",
       "\n",
       "   SPECIALTY TYPE  SPECIALTY SUBTYPE  \n",
       "0             NaN                NaN  \n",
       "1             NaN                NaN  \n",
       "0             NaN                NaN  \n",
       "1             NaN                NaN  \n",
       "0             NaN                NaN  \n",
       "1             NaN                NaN  \n",
       "2             NaN                NaN  \n",
       "0             NaN                NaN  \n",
       "1             NaN                NaN  \n",
       "2             NaN                NaN  \n",
       "0             NaN                NaN  \n",
       "1             NaN                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variables used to find and query feature layer in AGOL\n",
    "client_id = \"CrnxPfTcm7Y7ZGl7\"\n",
    "url = r\"https://services.arcgis.com/0L95CJ0VTaxqcmED/arcgis/rest/services/TRANSPORTATION_markings_{}/FeatureServer/0\"\n",
    "sl,sp = (pd.DataFrame(),pd.DataFrame())\n",
    "\n",
    "# Columns for data frame. Indexes: df (0-1), shortline (3-4), specialty point (5-7)\n",
    "cols = {'Location ID': 'LOCATION ID', 'Comments':'COMMENTS', 'MARKINGS_SHORT_LINE_ID': 'SHORTLINE ID',\n",
    "        'SHORT_LINE_TYPE': 'SHORTLINE TYPE', 'SEGMENT_ID': 'SEGMENT ID', 'MARKINGS_SPECIALTY_POINT_ID':'SPECIALTY ID',\n",
    "        'SPECIALTY_POINT_TYPE': 'SPECIALTY TYPE', 'SPECIALTY_POINT_SUB_TYPE': 'SPECIALTY SUBTYPE'}\n",
    "\n",
    "# Access markings feature layers to query and append as a single new data frame\n",
    "try:\n",
    "    gis = GIS(\"https://austin.maps.arcgis.com/home/index.html\",client_id=None)\n",
    "    for index,row in df.iterrows():\n",
    "        sl = query_df(FeatureLayer(url.format(\"short_line\")),index,list(cols)[2:5],df,sl)\n",
    "        sp = query_df(FeatureLayer(url.format(\"specialty_point\")),index,list(cols)[4:],df,sp)\n",
    "    markings = sl.append(sp,sort=True).reindex(columns=list(cols))\n",
    "    markings.columns = list(cols.values())\n",
    "    display(markings)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe lists pavement markings queried by segment IDs with the following columns:\n",
    "- <i>LOCATION ID</i>: Unique identifier used for street paving\n",
    "- <i>COMMENTS</i>: Notes on long line markings\n",
    "- <i>SHORTLINE ID</i>: Unique identifier used for short line markings\n",
    "- <i>SHORTLINE TYPE</i>: Type of short line (crosswalk, stop line, yield line, etc.)\n",
    "- <i>SEGMENT ID</i>: Segment ID where the markings is located\n",
    "- <i>SPECIALTY ID</i>: Unique identifier used for specialty point markings\n",
    "- <i>SPECIALTY TYPE</i>: Type of specialty marking domain code (Arrow, Symbol, Word, etc.)\n",
    "- <i>SPECIALTY SUBTYPE</i>: Subtype of specialty marking domain code (Left turn, Bicyclist, Stop, etc.)\n",
    "\n",
    "The dataframe will be saves in an excel sheet for it to be used again to generate the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(filename = excel_file)\n",
    "sheet_name = \"markings list\"\n",
    "if sheet_name in wb:\n",
    "    ws = wb[sheet_name]\n",
    "else:\n",
    "    ws = wb.create_sheet(sheet_name)\n",
    "    for r in dataframe_to_rows(markings, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    wb.save(excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Whereabouts Plans\n",
    "To generate whereabout plans, we will have to use the `arcpy` package, which requires Python 2 and ArcMap 10.5. Eventually, this notebook will be able to use `arcpy` in Python 3.\n",
    "\n",
    "[Click here to access notebook](PlansTemplate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spreadsheet of Completed Streets\n",
    "This is intended to report on extracted streets generated from the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Columns of extracted table\n",
    "columns = [\"Location ID\", \"Street\", \"From\", \"To\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df.read_excel(FOLDER + \"\\\\SBO Street List.xlsx\")\n",
    "except:\n",
    "    for foldername,subfolders,files in os.walk(FOLDER):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                df1 = pdf_table_to_df(columns)\n",
    "                df1[\"filename\"] = file\n",
    "                df = df.append(df1,sort=True)\n",
    "    df.to_excel(FOLDER + \"\\\\SBO Street List.xlsx\",sheet_name=\"Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
