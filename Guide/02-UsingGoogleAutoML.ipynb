{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google Auto ML\n",
    "This is a document that outlines how to get started on creating a custom object detector using Google's AutoML API (https://cloud.google.com/automl).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- A Google Cloud account in the Free Tier. See https://cloud.google.com/free/docs/gcp-free-tier\n",
    "- Billing Information (Google claims it will not auto charge to card if doing a free trial. The free trial lasts until $300 credit is used up or until a year has past since sign up).\n",
    "- Python. Supported versions are 3.5 to 3.7, and 2.7.9 or higher. Recommend >= 3.6 \n",
    "- Linux, macOS, or Windows device \n",
    "Cloud SDK requires Python. Some tools bundled with Cloud SDK have additional requirements\n",
    "\n",
    "## Documentation\n",
    "https://cloud.google.com/vision/automl/object-detection/docs?hl=en_US\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Data (Photo Example)\n",
    "The Google AutoML API accepts photos and screenshots from videos to train your custom object detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import automl\n",
    "from google.cloud import automl_v1beta1\n",
    "from google.cloud.automl_v1beta1.proto import service_pb2\n",
    "import io\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.getcwd()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/SusanneGov/Documents/My First Project-bcfca3ee21b0.json\" # replace with your JSON path\n",
    "project_id = \"micro-progress-275116\"\n",
    "bucket_name = \"overhead-signs\" # The name you want the photos to be put in Google Cloud storage\n",
    "folders = ['test_photos'] # Add local folder name or multiple folders used for training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an CSV of unlabeled images from an existing folder on the local computer. For the guide, we will be using the 'test_photos' folder. The CSV columns are set to 10 columns.\n",
    "\n",
    "<b>label,image_path,x1,y1,None,None,x2,y2,None,None</b>\n",
    "- label is the label for bounding box\n",
    "- image_path is the Google Cloud Storage path\n",
    "- x1/x2 and y1/y2 are coordinates of bounding box\n",
    "- None is simply blank column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_list = [] # keep it empty \n",
    "for f in folders:\n",
    "    google_url = r'gs://{0}/{1}/'.format(bucket_name,f)\n",
    "    for file in glob.glob(FILE_PATH + \"//\" + f + '/*.png'):\n",
    "        value = (google_url + os.path.basename(file),\n",
    "                 '','','','','','','','','')\n",
    "        png_list.append(value)  \n",
    "png_df = pd.DataFrame(png_list)\n",
    "png_df['set'] = 'UNASSIGNED'\n",
    "output_csv = FILE_PATH + \"//\" + bucket_name + \"-\" + datetime.now().strftime(\"%m%d%Y\") + \".csv\"\n",
    "png_df.set_index('set').to_csv(output_csv,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Photos and CSV file in Google Cloud Storage\n",
    "After the CSV has been created, you need to upload the photos and CSV you plan to use to train your object detector onto the Google Cloud Storage https://console.cloud.google.com/storage \n",
    "\n",
    "1) Set up a \"bucket\" to put the folder(s) of photos and csv files in.\n",
    "\n",
    "![photo](6.png)\n",
    "\n",
    "2) After bucket has been created, we can start importing the folder containing photos and the CSV file created in Python.\n",
    "\n",
    "![photo](7.png)\n",
    "\n",
    "3) Visit the Google Vision console, go to \"Datasets\", and select \"New Dataset\" button to create a dataset.\n",
    "\n",
    "![photo](8.png)\n",
    "\n",
    "4) Select the type of model object you want to have for this datatset.\n",
    "- Single-Label Classificiation: Good for detecting a single label in one photo. Good if you are not expecting more than one label for photos such as datasets with preset labels already created. Fastest in training and detecting. Highly recommend that the photos used for training show only the label.\n",
    "- Multi-Label Classification: Good for detecting multiple labels in a single photos. Good for detecting multiple attributes in a single photo. Also fast in training and detecting. Highly recommend that the photos used for training show only the label(s).\n",
    "- Object Detection: Good for detecting objects in \"cluttered\" photos with bounding boxes. Recommended if using video frames as photos or streetview imagery or need to measure the object itself. Requires several hours or longer in training depending on the size of dataset.\n",
    "\n",
    "![photo](9.png)\n",
    "\n",
    "5) After dataset has been created, select the new dataset, go to the \"Import\" tab,.\n",
    "- If you havn't imported photos yet, select \"Upload images from computer\" otherwise and then \"Select a CSV file on Cloud storage\" option.\n",
    "- After that, navigate to CSV file import and Google Vision will show a download bar. This might take a while for big datasets, so feel free to take a coffee break or something. You do need to watch it though in case errors pop up.\n",
    "\n",
    "See this video (4:15) which explains the general concepts for Single/Multi-Label Classification: https://www.youtube.com/watch?v=_2eG8xpRYZ4\n",
    "\n",
    "6) After the CSV has finished sucessfully uploading the photos from Google Cloud storage to the dataset, we are going to start labelling the images using Google's Web UI tool on the Google Chrome browser under the Images tab.\n",
    "\n",
    "<b> This requires Google Chrome! NO Firefox, Microsoft Edge, Internet Explorer, or Safari</b>\n",
    "\n",
    "![photo](10.png)\n",
    "\n",
    "7) Use the \"Add a new label\" to add labels. Use the mouse to clock on the photo and drag the bounding box to the object you want labelled in each photo. You can check how many labels used throught the \"Label Stats\" button\n",
    "\n",
    "![photo](11.png)\n",
    "\n",
    "Optional: If you don't want to do it manually, Google has the \"Data Labelling\" service where you can spend credits to have someone at Google label the images for you if you provide them with good documentation in a PDF file. I have not used it, but this is an option if you don't have time to label large datasets of photos. https://console.cloud.google.com/data-labeling/\n",
    "\n",
    "7) After youn finished labelling a sufficient amount of photos for training, select the \"Export Data\" button to export your labeled photo information into a CSV format on Google Cloud Storage. This is important so that it saves the bounding box information for future use, or for removing labels that are not sufficient for training (which will be explained in next step).\n",
    "\n",
    "![photo](12.png)\n",
    "\n",
    "8) Before you can train the model, go to the \"Label Stats\" button and see if all the labels have reached sufficient amount for training. Any warning icons on the label means that Google will not be able to to run training on your custom object detector. It is recommened to have at least 1000 bounding boxes per label for the highest accuracy, but 100 would be sufficient. Google accepts 10 at a minimum but it has very low accuracy.\n",
    "\n",
    "<b> Basically you don't want this.</b>\n",
    "\n",
    "![photo](13.png)\n",
    "\n",
    "<b> Try to get this </b>\n",
    "\n",
    "![photo](14.png)\n",
    "\n",
    "Unfortunately, the Vision AutoML is still in Beta so the only way to fix the warning icon is to either add more photos of that label or to remove the label itself from training. That is why it is important to use the \"Export Data\" function to use the CSV in cases where there is not enough photos for a particular label to save your progress.\n",
    "\n",
    "9) After the photos have been labeled and the labels Stats do not show any warning errors, the next step is to train the dataset in the Train tab.\n",
    "\n",
    "![photo](15.png)\n",
    "\n",
    "This may take 1-10 hours depending on how big the dataset is for training.\n",
    "\n",
    "11) You can see the results of training in the Evaluate tab.\n",
    "\n",
    "![photo](16.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our custom object detector\n",
    "After training, your custom object detector is ready to be used on various photos. Google allows onject detection of individual photos through their Web UI or multiple photos from coding\n",
    "\n",
    "After training is complete, you can start deploying your model BUT <b> once your model is deployed, Google will start billing the hours of deployment for your model.</b>\n",
    "\n",
    "For now, we are going to prepare the photos to use for our custom object detector. First setup google application credentials via Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials to access Google Applications\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= \"/Users/SusanneGov/Documents/My First Project-bcfca3ee21b0.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start deploying your model through the Google console tab Test & Use.\n",
    "\n",
    "![photo](17.png)\n",
    "\n",
    "I created a method to return predictions from the model. For your own custom object detector, replace the `project_id` and `model_id` variables with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to create predictio from deployed model\n",
    "def get_prediction(content):\n",
    "    project_id = \"micro-progress-275116\" # your project id\n",
    "    model_id = \"IOD7288297542666682368\" # your model id\n",
    "    prediction_client = automl_v1beta1.PredictionServiceClient()\n",
    "    name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)\n",
    "    payload = {'image': {'image_bytes': content }}\n",
    "    params = {}\n",
    "    request = prediction_client.predict(name, payload, params)\n",
    "    return request  # waits till request is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `file_path` variable with the folder of photos you want to use the custom object detector on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates empty dictionary to input object detection info\n",
    "file_path = FILE_PATH + \"/SignPhotos\"\n",
    "info = {}\n",
    "# for loop of all photos in folder\n",
    "for filename in os.listdir(file_path):\n",
    "    if filename.endswith(\".png\"): \n",
    "        with open(FILE_PATH + \"/SignPhotos/\" + filename, \"rb\") as content_file:\n",
    "            content = content_file.read()\n",
    "        data = get_prediction(content)\n",
    "        name = set() # to prevent duplicate sign detection from other directions\n",
    "        for result in data.payload:\n",
    "            name.add(result.display_name)\n",
    "        info[filename] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After code above finishes running, export results as a excel file. You can replace the `output_file` path name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = FILE_PATH + r\"/results.xlsx\"\n",
    "temp_df = pd.DataFrame.from_dict(info,orient=\"index\").sort_index()\n",
    "temp_df.to_excel(output_file, sheet_name='Sign Objects')\n",
    "display(temp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
