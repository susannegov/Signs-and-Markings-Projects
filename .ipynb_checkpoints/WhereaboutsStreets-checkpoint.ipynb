{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Whereabout Streets Data Extraction\n",
    "This notebook will demonstrate how to access Street and Bridge Operations PDF file and extract this data to create a work order plan template.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://upload.wikimedia.org/wikipedia/en/9/94/Closeup_of_pavement_with_grass.JPG\" /></div>\n",
    "\n",
    "## Introduction\n",
    "The purpose of this notebook is to create a Street and Bridge Work Order plans based on segment IDs and additional comments on long line. Markings feature layers are published in the City of Austin ArcGIS Portal page available for public view as well. \n",
    "\n",
    "The schedule for where sealcoat and overlay streets are completed is received through email by Street and Bridge Operations on a daily basis. It is sent as a PDF file that lists weather conditions, temperature, and provides a table of streets where paving is completed.\n",
    "\n",
    "<b>The only manual process the user will have to do is to:</b>\n",
    "- Input Segment IDs\n",
    "- Make comments on long line markings\n",
    "- Specify MONTH/DAY/YEAR to retrieve the table of completed streets paved for PDF name and file path\n",
    "- Create any missing markings assets that are not visible in aerial imagery\n",
    "\n",
    "This process will cut down on the previous process of manually editing a plans layout through copy-pasting imagery and writing Location IDs, work groups, markings found, and the exporting plans one at a time. An excel document will be created based on this input and read segment IDs to find all short line and specialty point markings. This will ideally generate multiple PDF plans in a faster and shorter time frame.\n",
    "\n",
    "In the future I would like to make this script more customizable and be done seamlessly without inputting Segment IDs and inputting only specific long line markings using the maintained streets feature layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "The packages used for this project are:\n",
    "- [exchangelib](https://github.com/ecederstrand/exchangelib) to access the attachments sent by Street and Bridge Operations\n",
    "- [pdfplumber](https://github.com/jsvine/pdfplumber) to extract tables from the whereabouts report\n",
    "- [pandas](https://pandas.pydata.org/) to create dataframe of extracted table and transform the data\n",
    "- [openpyxl](https://openpyxl.readthedocs.io/en/stable/) to edit excel files\n",
    "- [arcgis](https://esri.github.io/arcgis-python-api/apidoc/html/) to search for markings feature layer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exchangelib import DELEGATE, Account, Credentials, Configuration, FileAttachment, ItemAttachment\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from openpyxl import Workbook,load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "The date by month and day constant will determine the file pdf name to use as a dataframe. Folder path will determine where the plans will be created depending on the year. This is set to the top for the purpose of changing these constants as needed.\n",
    "\n",
    "<i>The table below explains the purpose of each constant.</i>\n",
    "\n",
    "| Constant | Description   |\n",
    "|:--------:|----|\n",
    "| <b>MONTH, DAY, YEAR</b> |Date used to find PDF in month-day format and file path based on year|\n",
    "|<b>FOLDER</b>      |File directory used to import SBO whereabouts reports from email|\n",
    "|<b>FILE_NAME</b>   |File directory name used to extact SBO whereabouts reports from file|\n",
    "|<b>SIGN_IN</b>   |Whether to prompt user to sign in to outlook email|\n",
    "|<b>INPUT</b>|Whether to prompt user to input segment Ids and comments to export to excel| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'MONTH' (str)\n",
      "Stored 'DAY' (str)\n",
      "Stored 'YEAR' (str)\n",
      "Stored 'FOLDER' (str)\n",
      "Stored 'FILE_NAME' (str)\n"
     ]
    }
   ],
   "source": [
    "MONTH,DAY,YEAR = ('Aug',str(2),str(2019))\n",
    "FOLDER = (r\"G:\\ATD\\Signs_and_Markings\\MARKINGS\\Whereabouts WORK ORDERS\\{}\\Whereabouts_Summary\").format(YEAR)\n",
    "FILE_NAME = \"\\\\\".join((FOLDER,\" \".join((MONTH,DAY))))\n",
    "SIGN_IN = False\n",
    "INPUT= True\n",
    "\n",
    "%store MONTH\n",
    "%store DAY\n",
    "%store YEAR\n",
    "%store FOLDER\n",
    "%store FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "These functions will be used to extract and transform the data into a feasible format.\n",
    "\n",
    "<i>The table below explains the purpose of each:</i>\n",
    "\n",
    "| Method | Description   |\n",
    "|:--------:|----|\n",
    "|<b>lists_to_df</b> |Converts extracted nested list into a dataframe|\n",
    "|<b>pdf_table_to_df</b> |Extracts table from PDF and then converts to dataframe|\n",
    "|<b>input_form</b> |Prompts user to input segment IDs and long line specifications|\n",
    "|<b>query_df</b>   |Query dataframe by segment IDs|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns dataframe of transformed extracted table\n",
    "def lists_to_df(data,columns):\n",
    "    l = [item for sublist in data for item in sublist]\n",
    "    l = [[ x for x in y if x != None and x != ''] for y in l] \n",
    "    l = [x for x in l if x[0] != 'ID#']\n",
    "    for i in l:\n",
    "        if i[0].isdigit() == False:\n",
    "            del i[0]\n",
    "        del i[len(columns):len(i)]\n",
    "    df = pd.DataFrame(l,columns=columns)\n",
    "    return df\n",
    "\n",
    "# Opens PDF to extract table and convert to dataframe\n",
    "def pdf_table_to_df(columns):\n",
    "    with pdfplumber.open(FILE_NAME + \".pdf\") as pdf:\n",
    "        pg1 = pdf.pages[0]\n",
    "        data = pg1.extract_tables(table_settings={})\n",
    "        df = lists_to_df(data,columns)\n",
    "        pdf.close()\n",
    "        return df\n",
    "\n",
    "# Prompts user to input segment IDs and comments while changing the datafram to include user input\n",
    "def input_form(df,columns):\n",
    "    segments, comments = [],[]\n",
    "    for index,row in df.iterrows():\n",
    "        location = \"{} from {} to {}\".format(row[\"Street\"],row[\"From\"],row[\"To\"])\n",
    "        console = input(location + \"\\nSegment ID list: \")\n",
    "        try:\n",
    "            # list_s = list(map(int, console.split('\\t'))) if copy pasting\n",
    "            list_s = list(map(int, console.split(','))) # if exists\n",
    "            segments.append(console)\n",
    "        except ValueError:\n",
    "            print(\"Skipping input...\")\n",
    "            segments.append(None)\n",
    "        comment = input(\"Comment: \")\n",
    "        comments.append(comment)\n",
    "    df['Segment IDs'], df['Comments'] = ([s.replace('\\t',',') if s != None else None for s in segments ],comments)\n",
    "    print(\"\\nInput complete.\")\n",
    "    \n",
    "# Returns query dataframe appended if markings exist in the listed segment IDs\n",
    "def query_df(fc,index,f,df,df1):\n",
    "    q = \"SEGMENT_ID IN({})\".format(df[\"Segment IDs\"][index])\n",
    "    if q != \"SEGMENT_ID IN(N/A)\":\n",
    "        c = fc.query(where=q,return_count_only=True) \n",
    "        if c != 0:\n",
    "            sdf = fc.query(where=q).sdf.filter(items=f)\n",
    "            sdf[\"Location ID\"] = df[\"Location ID\"][index]\n",
    "            df1 = df1.append(sdf)\n",
    "    return df1\n",
    "\n",
    "# Return pivot table dataframe of counts for each markings\n",
    "def markings_count(df,group,columns,wg):\n",
    "    df = df.groupby(group).count()[['SEGMENT_ID']].rename(columns={\"SEGMENT_ID\":'COUNTS'})\n",
    "    df = df.pivot_table(values='COUNTS',index='Location ID',columns=columns,aggfunc='first').reset_index()\n",
    "    df[wg] = wg\n",
    "    return df\n",
    "\n",
    "# Rename panda columns based on markings assets domain codes\n",
    "def rename_markings_col(df):\n",
    "    renameList = list(df.columns)\n",
    "    arrow = [\n",
    "        \"Through\",\"Left \",\"Right\",\"Left and Right\",\"Left, Right and Through\",\"Left and Through\", \"Right and Through\",\n",
    "        \"U-turn\",\"Lane reduction\", \"Wrong way\",\"Bike\"]\n",
    "    other = [\"Green pad\", \"Green launch pad\", \"Speed hump marking\",\"Diagonal crosshatch\", \"Chevron crosshatch\"]\n",
    "    parking = [\"Parking 'L'\", \"Parking 'T'\", \"Parking stall line\", \"Handicap symbol\"]\n",
    "    symbol = [\n",
    "        \"Bicycle (Bike)\",\"Shared lane (Sharrow)\", \"Bicyclist\",\"Railroad Crossing (RxR)\", \"Chevron\",\"Pedestrian\", \"Diamond\"]\n",
    "    word = [\"Stop\", \"Yield\", \"Ahead\", \"Only\", \"Merge\",\"Ped\", \"X-ing\",\"Bus Only\", \"Keep Clear\", \"Do Not Block\", \"Ped X-ing\"]\n",
    "    t =['word','arrow','symbol','','parking']\n",
    "    st = [word,arrow,symbol,other,parking]\n",
    "    index = 0\n",
    "    for i in renameList:\n",
    "        if isinstance(i,tuple):\n",
    "            x = list(map(int,list(i)))\n",
    "            temp = st[x[0] - 1][x[1] - 1] + \" \" + t[x[0] - 1]\n",
    "            renameList[index] = temp\n",
    "        elif i == 'STOP_LINE' or i == 'CROSSWALK':\n",
    "            temp = i.capitalize().replace('_','')\n",
    "            renameList[index] = temp\n",
    "        index += 1\n",
    "    df.columns = renameList\n",
    "    return df\n",
    "\n",
    "# Return dataframe of the listed specifications\n",
    "def specifications(df):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Loading and Transforming Data\n",
    "\n",
    "### Email Attachment Extraction\n",
    "\n",
    "Attachments will be extracted from the inbox. The purpose of `getpass` is to prompt the user for a password to login to email. \n",
    "\n",
    "Since the attachments have already been exported to the directory file, a sign-in is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Email subject line used for Street and Bridge Whereabouts report\n",
    "daily_subject = \"S&B Whereabouts\"\n",
    "\n",
    "# This will try to prompt the user to input email and password if SIGN_IN is True\n",
    "try:\n",
    "    if SIGN_IN:\n",
    "        email = input(\"Enter email: \")\n",
    "        password = getpass.getpass(\"Enter password: \")\n",
    "        credentials = Credentials(username = email,password = password)\n",
    "        config = Configuration(server='outlook.office365.com', credentials=credentials)\n",
    "        account = Account(\n",
    "            primary_smtp_address=email,\n",
    "            config=config,\n",
    "            autodiscover=False,\n",
    "            access_type=DELEGATE)\n",
    "        print(\"\\nFile attachments below are:\")\n",
    "        for item in account.inbox.filter(subject__contains=daily_subject):\n",
    "            for attachment in item.attachments:\n",
    "                if isinstance(attachment, FileAttachment):\n",
    "                    file_path = \"\\\\\".join([FOLDER,attachment.name])\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(attachment.content)\n",
    "                    print(file_path)\n",
    "except:\n",
    "    print(\"\\nWrong username or password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF tables to Excel\n",
    "\n",
    "Now that the PDFs have been extracted and exported to the folder path, the next step is to extract the tables in the PDF and export it as an excel file.\n",
    "\n",
    "An input form will generate so the user can input Segment ID and comment information for each of the streets listed. The columns list will only take the relevant columns from the extracted table. The `pdfplumber` package will be used to extract tables from the PDF and prompt user to submit data.\n",
    "\n",
    "The input will be stored as a DataFrame saved to an excel document. If the user already provided input froma  previous session, the dataframe will be set to the excel file document instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Columns of extracted table\n",
    "columns = [\"Location ID\", \"Street\", \"From\", \"To\"]\n",
    "excel_file = FILE_NAME + \".xlsx\"\n",
    "        \n",
    "# Will prompt input and export to excel unless the excel file already exists. In that case it will read excel file instead\n",
    "if Path(excel_file).exists():\n",
    "    df = pd.read_excel(excel_file,index_col=0)\n",
    "    df = df.fillna(\"N/A\")\n",
    "else:\n",
    "    if INPUT:\n",
    "        df = pdf_table_to_df(columns)\n",
    "        input_form(df,columns)\n",
    "        df = df.fillna(\"N/A\")\n",
    "        df.to_excel(excel_file,sheet_name=\" \".join((MONTH,DAY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Segment IDs</th>\n",
       "      <th>Comments</th>\n",
       "      <th>LONGLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lakeshore</td>\n",
       "      <td>Royal Crest</td>\n",
       "      <td>0.5 LM</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALL ST</td>\n",
       "      <td>Cross Park Dr</td>\n",
       "      <td>Ferguson Ln</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2040261</td>\n",
       "      <td>turn bay, lane lines, double yellow dashed sol...</td>\n",
       "      <td>LONGLINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62870</td>\n",
       "      <td>DAVIS LN</td>\n",
       "      <td>4304</td>\n",
       "      <td>Mo-Pac Svc Rd Nb</td>\n",
       "      <td>2026275,2038344,2038345,2043055,3259330,325933...</td>\n",
       "      <td>lane lines, bike lanes, turn bay</td>\n",
       "      <td>LONGLINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62872</td>\n",
       "      <td>DEER LN</td>\n",
       "      <td>4000</td>\n",
       "      <td>4313</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location ID         Street         From                To  \\\n",
       "0   Lakeshore    Royal Crest       0.5 LM               N/A   \n",
       "1     WALL ST  Cross Park Dr  Ferguson Ln              3.89   \n",
       "2       62870       DAVIS LN         4304  Mo-Pac Svc Rd Nb   \n",
       "3       62872        DEER LN         4000              4313   \n",
       "\n",
       "                                         Segment IDs  \\\n",
       "0                                                N/A   \n",
       "1                                            2040261   \n",
       "2  2026275,2038344,2038345,2043055,3259330,325933...   \n",
       "3                                                N/A   \n",
       "\n",
       "                                            Comments  LONGLINE  \n",
       "0                                                N/A       NaN  \n",
       "1  turn bay, lane lines, double yellow dashed sol...  LONGLINE  \n",
       "2                   lane lines, bike lanes, turn bay  LONGLINE  \n",
       "3                                                N/A       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a table for the list of streets with the following columns:\n",
    "- <i>Location ID</i>: unique identifier used for street paving\n",
    "- <i>Street</i>: main street that is paved\n",
    "- <i>From</i>: intersecting cross street\n",
    "- <i>To</i>: intersecting cross street\n",
    "- <i>Segment IDs</i>: list of segment IDs where street is paved seperated by commas\n",
    "- <i>Comments</i>: Notes on long line markings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Layer Data Query\n",
    "\n",
    "The next task is to find the markings through the list of segment IDs the user has inputted. For this task the `arcgis` package will be useful for extracting the markings available in each segment ID since the dataset is already available publically.\n",
    "\n",
    "Since the markings datasets are publically available, we can login to ArcGIS Online anonymously. \n",
    "\n",
    "Use `client_id` instead of `None` if you wish to log-in through an AGOL federate account. Note that it will prompt user to enter code which can be found by following the instructions. Going through an AGOL federated account is useful if the user wishes to add their own layers as a reference such as [NearMap](https://go.nearmap.com/) aerial imagery. \n",
    "\n",
    "It will search through the markings feature layer based on the list of segment IDs provided by the excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# variables used to find and query feature layer in AGOL\n",
    "client_id = \"CrnxPfTcm7Y7ZGl7\"\n",
    "url = r\"https://services.arcgis.com/0L95CJ0VTaxqcmED/arcgis/rest/services/TRANSPORTATION_markings_{}/FeatureServer/0\"\n",
    "sl,sp,cover = (pd.DataFrame(),pd.DataFrame(),df)\n",
    "wg = ['SHORT LINE','SPECIALTY MARKINGS','LONGLINE']\n",
    "\n",
    "# Columns for data frame. Indexes: df (0), shortline (1-4), specialty point (3 to etc.)\n",
    "cols = ['Location ID', 'MARKINGS_SHORT_LINE_ID','SHORT_LINE_TYPE', 'SEGMENT_ID', \n",
    "        'MARKINGS_SPECIALTY_POINT_ID','SPECIALTY_POINT_TYPE', 'SPECIALTY_POINT_SUB_TYPE']\n",
    "\n",
    "# Access markings feature layers to query and append as a single new data frame\n",
    "try:\n",
    "    gis = GIS(\"https://austin.maps.arcgis.com/home/index.html\",client_id=None)\n",
    "    for index,row in df.iterrows():\n",
    "        sl = query_df(FeatureLayer(url.format(\"short_line\")),index,cols[1:4],df,sl)\n",
    "        sp = query_df(FeatureLayer(url.format(\"specialty_point\")),index,cols[3:],df,sp)\n",
    "except:\n",
    "    pass\n",
    "sl = markings_count(sl,['Location ID','SHORT_LINE_TYPE'],('SHORT_LINE_TYPE'),wg[0])\n",
    "sp = markings_count(sp,['Location ID','SPECIALTY_POINT_TYPE','SPECIALTY_POINT_SUB_TYPE'],\n",
    "                    ('SPECIALTY_POINT_TYPE','SPECIALTY_POINT_SUB_TYPE'),wg[1])\n",
    "cover.loc[cover.Comments != 'N/A', wg[2]] = wg[2]\n",
    "cover = reduce(lambda z,y: pd.merge_ordered(z,y,on='Location ID'), [cover,sl,sp])\n",
    "cover = cover.dropna(how='all',subset=list(cover.columns)[6:])\n",
    "cover['WORK GROUPS'] = cover[[('SPECIALTY MARKINGS', ''),'LONGLINE','SHORT LINE']].astype(str).apply(','.join,1)\n",
    "cover['WORK GROUPS'] = cover['WORK GROUPS'].apply(lambda x: [s for s in x.split(',') if s != 'nan'])\n",
    "cover = cover.drop(columns =['SHORT LINE',('SPECIALTY MARKINGS', ''),'LONGLINE']).fillna('N/A')\n",
    "cover = rename_markings_col(cover).reset_index(drop=True)\n",
    "\n",
    "# Create specification table\n",
    "cover[\"Specifications\"] = ''\n",
    "for index,row in cover.iterrows():\n",
    "    keys = list(row[6:])\n",
    "    values = list(cover.columns)[6:]\n",
    "    spec = []\n",
    "    for k,v in zip(keys,values):\n",
    "        if k != 'N/A' and k != '' and v != 'WORK GROUPS':\n",
    "            spec.append('{} {}'.format(int(k),v.lower()))\n",
    "    sentence = 'Install {}'.format(row['Comments']) + ', '.join(word for word in spec)\n",
    "    cover.at[index,'Specifications'] = sentence\n",
    "cover['WORK GROUPS'] = cover['WORK GROUPS'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Segment IDs</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Crosswalk</th>\n",
       "      <th>Stopline</th>\n",
       "      <th>Only word</th>\n",
       "      <th>Left  arrow</th>\n",
       "      <th>Right arrow</th>\n",
       "      <th>Bike arrow</th>\n",
       "      <th>Bicyclist symbol</th>\n",
       "      <th>Diagonal crosshatch</th>\n",
       "      <th>WORK GROUPS</th>\n",
       "      <th>Specifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62870</td>\n",
       "      <td>DAVIS LN</td>\n",
       "      <td>4304</td>\n",
       "      <td>Mo-Pac Svc Rd Nb</td>\n",
       "      <td>2026275,2038344,2038345,2043055,3259330,325933...</td>\n",
       "      <td>lane lines, bike lanes, turn bay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['SPECIALTY MARKINGS', 'LONGLINE', 'SHORT LINE']</td>\n",
       "      <td>Install lane lines, bike lanes, turn bay1 cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALL ST</td>\n",
       "      <td>Cross Park Dr</td>\n",
       "      <td>Ferguson Ln</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2040261</td>\n",
       "      <td>turn bay, lane lines, double yellow dashed sol...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13.0</td>\n",
       "      <td>['SPECIALTY MARKINGS', 'LONGLINE', 'SHORT LINE']</td>\n",
       "      <td>Install turn bay, lane lines, double yellow da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location ID         Street         From                To  \\\n",
       "0       62870       DAVIS LN         4304  Mo-Pac Svc Rd Nb   \n",
       "1     WALL ST  Cross Park Dr  Ferguson Ln              3.89   \n",
       "\n",
       "                                         Segment IDs  \\\n",
       "0  2026275,2038344,2038345,2043055,3259330,325933...   \n",
       "1                                            2040261   \n",
       "\n",
       "                                            Comments  Crosswalk  Stopline  \\\n",
       "0                   lane lines, bike lanes, turn bay        1.0       2.0   \n",
       "1  turn bay, lane lines, double yellow dashed sol...        2.0       2.0   \n",
       "\n",
       "   Only word Left  arrow  Right arrow Bike arrow Bicyclist symbol  \\\n",
       "0        1.0         N/A          1.0         21                8   \n",
       "1        1.0           4          2.0        N/A              N/A   \n",
       "\n",
       "   Diagonal crosshatch                                        WORK GROUPS  \\\n",
       "0                  10.0  ['SPECIALTY MARKINGS', 'LONGLINE', 'SHORT LINE']   \n",
       "1                  13.0  ['SPECIALTY MARKINGS', 'LONGLINE', 'SHORT LINE']   \n",
       "\n",
       "                                      Specifications  \n",
       "0  Install lane lines, bike lanes, turn bay1 cros...  \n",
       "1  Install turn bay, lane lines, double yellow da...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe lists pavement markings queried by segment IDs with the following columns:\n",
    "- <i>LOCATION ID</i>: Unique identifier used for street paving\n",
    "- <i>COMMENTS</i>: Notes on long line markings\n",
    "- <i>SHORTLINE ID</i>: Unique identifier used for short line markings\n",
    "- <i>SHORTLINE TYPE</i>: Type of short line (crosswalk, stop line, yield line, etc.)\n",
    "- <i>SEGMENT ID</i>: Segment ID where the markings is located\n",
    "- <i>SPECIALTY ID</i>: Unique identifier used for specialty point markings\n",
    "- <i>SPECIALTY TYPE</i>: Type of specialty marking domain code (Arrow, Symbol, Word, etc.)\n",
    "- <i>SPECIALTY SUBTYPE</i>: Subtype of specialty marking domain code (Left turn, Bicyclist, Stop, etc.)\n",
    "\n",
    "The dataframe will be saves in an excel sheet for it to be used again to generate the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(filename = excel_file)\n",
    "sheet_name = \"markings list\"\n",
    "if sheet_name in wb:\n",
    "    ws = wb[sheet_name]\n",
    "else:\n",
    "    ws = wb.create_sheet(sheet_name)\n",
    "    for r in dataframe_to_rows(cover, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    wb.save(excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Whereabouts Plans\n",
    "To generate whereabout plans, we will have to use the `arcpy` package, which requires Python 2 and ArcMap 10.5. Eventually, this notebook will be able to use `arcpy` in Python 3.\n",
    "\n",
    "[Click here to access notebook](PlansTemplate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spreadsheet of Completed Streets\n",
    "This is intended to report on extracted streets generated from the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Columns of extracted table\n",
    "columns = [\"Location ID\", \"Street\", \"From\", \"To\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df.read_excel(FOLDER + \"\\\\SBO Street List.xlsx\")\n",
    "except:\n",
    "    for foldername,subfolders,files in os.walk(FOLDER):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                df1 = pdf_table_to_df(columns)\n",
    "                df1[\"filename\"] = file\n",
    "                df = df.append(df1,sort=True)\n",
    "    df.to_excel(FOLDER + \"\\\\SBO Street List.xlsx\",sheet_name=\"Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
