{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Whereabout Streets Data Extraction\n",
    "This notebook will demonstrate how to access Street and Bridge Operations PDF file and extract this data to create a work order plan template.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://upload.wikimedia.org/wikipedia/en/9/94/Closeup_of_pavement_with_grass.JPG\" /></div>\n",
    "\n",
    "## Introduction\n",
    "The purpose of this notebook is to create a Street and Bridge Work Order plans based on segment IDs and additional comments on long line. Markings feature layers are published in the City of Austin ArcGIS Portal page available for public view as well. \n",
    "\n",
    "The schedule for where sealcoat and overlay streets are completed is received through email by Street and Bridge Operations on a daily basis. It is sent as a PDF file that lists weather conditions, temperature, and provides a table of streets where paving is completed.\n",
    "\n",
    "<b>The only manual process the user will have to do is to:</b>\n",
    "- Input Segment IDs\n",
    "- Make comments on long line markings\n",
    "- Specify file path to retrieve the table of completed streets paved for PDF name and file path\n",
    "- Create any missing markings assets that are not visible in aerial imagery\n",
    "\n",
    "This process will cut down on the previous process of manually editing a plans layout through copy-pasting imagery and writing Location IDs, work groups, markings found, and the exporting plans one at a time. An excel document will be created based on this input and read segment IDs to find all short line and specialty point markings. This will ideally generate multiple PDF plans in a faster and shorter time frame.\n",
    "\n",
    "<i><b>Disclaimer:</b> This product is for informational purposes and may not have been prepared for or be suitable for legal, engineering, or surveying purposes. No warranty is made by the City of Austin regarding specific accuracy or completeness.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "The packages used for this project are:\n",
    "- [pandas](https://pandas.pydata.org/) to create dataframe of extracted table and transform the data\n",
    "- [openpyxl](https://openpyxl.readthedocs.io/en/stable/) to edit excel files\n",
    "- [arcgis](https://esri.github.io/arcgis-python-api/apidoc/html/) to search for markings feature layer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%run C:\\Users\\Govs\\Projects/CopyGISFeatures.py\n",
    "%run C:\\Users\\Govs\\Projects/FeatureLayerDataFrame.py\n",
    "    \n",
    "from openpyxl import Workbook,load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "from functools import reduce\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "The date by month and day constant will determine the file pdf name to use as a dataframe. Folder path will determine where the plans will be created depending on the year. This is set to the top for the purpose of changing these constants as needed.\n",
    "\n",
    "<i>The table below explains the purpose of each constant.</i>\n",
    "\n",
    "| Constant | Description   |\n",
    "|:--------:|----|\n",
    "| <b>MONTH, DAY, YEAR</b> |Date used to find PDF in month-day format and file path based on year|\n",
    "|<b>FOLDER</b>      |File directory used to import SBO whereabouts reports from email|\n",
    "|<b>FILE_NAME</b>   |File directory name used to extact SBO whereabouts reports from file|\n",
    "|<b>SIGN_IN</b>   |Whether to prompt user to sign in to outlook email|\n",
    "|<b>INPUT</b>|Whether to prompt user to input segment Ids and comments to export to excel| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'FOLDER' (str)\n",
      "Stored 'EXCEL_FILE' (str)\n"
     ]
    }
   ],
   "source": [
    "YEAR = str(2020)\n",
    "FOLDER = (r\"G:\\ATD\\Signs_and_Markings\\MARKINGS\\Whereabouts WORK ORDERS\\{}\"\n",
    "         ).format(YEAR)\n",
    "FILE_NAME = FOLDER + r'\\08_August\\sbo'\n",
    "EXCEL_FILE = FILE_NAME + '.xlsx'\n",
    "CSV_FILE = FILE_NAME + \".csv\"\n",
    "INPUT= True\n",
    "%store FOLDER\n",
    "%store EXCEL_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "These functions will be used to extract and transform the data into a feasible format.\n",
    "\n",
    "<i>The table below explains the purpose of each:</i>\n",
    "\n",
    "| Method | Description   |\n",
    "|:--------:|----|\n",
    "|<b>input_form</b> |Prompts user to input segment IDs and long line specifications|\n",
    "|<b>query_df</b>   |Query dataframe by segment IDs|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts user to input segment IDs and longline while changing the datafram to include user input\n",
    "def input_form(df):\n",
    "    segments = []\n",
    "    longline = []\n",
    "    for index,row in df.iterrows():\n",
    "        console = input(row['Location'] + \"\\nSegment ID list: \")\n",
    "        if not console:\n",
    "            segments.append(None)\n",
    "            longline.append(None)\n",
    "        else:\n",
    "            temp = GISFeatures(console).to_df()\n",
    "            segments.append(str(list(temp.SEGMENT_ID))[1:-1])\n",
    "            comment = input(\"Longline: \")\n",
    "            longline.append(comment)\n",
    "    df['Segment IDs'], df['LongLine'] = (segments,longline)\n",
    "    print(\"\\nInput complete.\")\n",
    "    return df.dropna(subset=['Segment IDs'])\n",
    "    \n",
    "# Returns query dataframe appended if markings exist in the listed segment IDs\n",
    "def query_df(fc,index,f,df,df1):\n",
    "    q = \"SEGMENT_ID IN('{})\".format(df[\"Segment IDs\"][index])\n",
    "    if q != \"SEGMENT_ID IN(N/A)\":\n",
    "        c = fc.query(where=q,return_count_only=True) \n",
    "        if c != 0:\n",
    "            sdf = fc.query(where=q).sdf.filter(items=f)\n",
    "            sdf[\"Location ID\"] = df[\"Location ID\"][index]\n",
    "            sdf[\"LongLine\"] = df[\"LongLine\"][index]\n",
    "            df1 = df1.append(sdf,sort=True)\n",
    "    df1['COUNTS'] = 1\n",
    "    return df1\n",
    "\n",
    "# Return dataframe of the listed specifications\n",
    "def specifications(df,i):\n",
    "    df[\"SPECIFICATIONS\"] = ''\n",
    "    for index,row in df.iterrows():\n",
    "        keys = list(row[i:])\n",
    "        values = list(df.columns)[i:]\n",
    "        spec = []\n",
    "        for k,v in zip(keys,values):\n",
    "            if k != 'N/A' and k != '' and v != 'WORK GROUPS':\n",
    "                spec.append('{} {}'.format(int(k),v.lower().replace('_',' ')))\n",
    "            if row['LongLine'] != 'N/A':\n",
    "                sentence = 'Install {}, '.format(row['LongLine']) + ', '.join(word for word in spec)\n",
    "            else:\n",
    "                sentence = 'Install ' + ', '.join(word for word in spec)\n",
    "        df.at[index,'SPECIFICATIONS'] = sentence\n",
    "    if 'WORK GROUPS' in df.columns:\n",
    "        df.loc[df.Street != None,'WORK GROUPS'] = df.loc[df.Street != None,'WORK GROUPS'].apply(str)\n",
    "    return df\n",
    "\n",
    "# Returns dataframe of markings count and pages\n",
    "def location_in_df(df,markings_type,workgroup):\n",
    "    if 'Location ID' in df:\n",
    "        count = df.groupby(['Location ID',markings_type]).count()[['SEGMENT_ID']].rename(columns={\"SEGMENT_ID\":'COUNTS'})\n",
    "        count = count.pivot_table(values='COUNTS',index='Location ID',columns=(markings_type),aggfunc='first').reset_index()\n",
    "        count[workgroup] = workgroup\n",
    "        page = df.groupby(['Location ID','SEGMENT_ID','LongLine',markings_type]).count()[['COUNTS']]\n",
    "        page = page.pivot_table(\n",
    "            values='COUNTS',index=['Location ID','SEGMENT_ID','LongLine'],columns=(markings_type),aggfunc='first')\n",
    "        return count,page\n",
    "\n",
    "# Returns dataframe of cover page\n",
    "def create_cover(cover,sl_count,sp_count,wg):\n",
    "    cover.loc[cover.LongLine != 'N/A', wg[2]] = wg[2]\n",
    "    cover.loc[cover.LongLine == 'N/A', wg[2]] = 'N/A' \n",
    "    if not sl_count.empty and not sp_count.empty:\n",
    "        cover = reduce(lambda z,y: pd.merge_ordered(z,y,on='Location ID'), [cover,sl_count,sp_count])\n",
    "    elif not sl_count.empty or not sp_count.empty:\n",
    "        count = sl_count if sp_count.empty else sp_count\n",
    "        wg_remove = 'SPECIALTY MARKINGS' if sp_count.empty else 'SHORTLINE'\n",
    "        cover = pd.merge_ordered(count,sl_count,on='Location ID')\n",
    "        wg.remove(wg_remove)\n",
    "    else:\n",
    "        cover = specifications(cover,9)\n",
    "        return cover\n",
    "    cover = cover.dropna(how='all',subset=list(cover.columns)[6:]).fillna('N/A')\n",
    "    cover['WORK GROUPS'] = cover[wg].apply(','.join,1).apply(lambda x: [s for s in x.split(',') if s != 'N/A'])\n",
    "    cover = cover.drop(columns = wg).fillna('N/A')\n",
    "    cover = specifications(cover,9)\n",
    "    cover['PAGE'] = 1\n",
    "    return cover[cover['WORK GROUPS'] != '[]']\n",
    "\n",
    "# Returns dataframe of pages\n",
    "def create_pages(pages,sl_page,sp_page):\n",
    "    if not sl_page.empty and not sp_page.empty: # if it has shortline and specialty\n",
    "        pages = pd.merge_ordered(sl_page,sp_page,on=('Location ID','SEGMENT_ID','LongLine')).fillna(\"N/A\")\n",
    "        pages = specifications(pages,3)\n",
    "        pages = pd.merge_ordered(pages,streets,on=('Location ID','SEGMENT_ID','LongLine'))\n",
    "        pages = pages.sort_values(by=['Location ID','BLOCK']).drop(columns='BLOCK').reset_index(drop = True)\n",
    "    elif not sl_page.empty or not sp_page.empty: # if it has shortline or specialty\n",
    "        page = sl_page if sp_page.empty else sp_page\n",
    "        pages = specifications(page.fillna('N/A'),3)\n",
    "        pages = pd.merge_ordered(pages,streets,on=('Location ID','SEGMENT_ID','LongLine')).sort_values(\n",
    "            by=['BLOCK','Location ID']).reset_index(drop = True).drop(columns='BLOCK')\n",
    "        pages = pages.dropna(subset=['SPECIFICATIONS'])\n",
    "        page = 1\n",
    "        for index, row in streets.iterrows():\n",
    "            if index != 0 and (row['Location ID'] != pages['Location ID'][index - 1]):\n",
    "                page = 2\n",
    "                pages.at[index,'PAGE'] = page\n",
    "            else:\n",
    "                page += 1\n",
    "                pages.at[index,'PAGE'] = page\n",
    "    else:\n",
    "        pages.loc[cover.Street != None,'PAGE'] = 2\n",
    "    return pages\n",
    "\n",
    "# Creates worksheet in excel file unless the worksheet already exists\n",
    "def create_ws(df,sheet_name):\n",
    "    if sheet_name in wb:\n",
    "        del wb[sheet_name]\n",
    "    ws = wb.create_sheet(sheet_name)\n",
    "    for r in dataframe_to_rows(df, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    wb.save(EXCEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SBO Report\n",
    "The first thing to do is to import the sbo report from a csv file and convert it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'wonum':'Location ID','on_street':'Street','from_street':'From','to_street':'To','actfinish_1':'Finish Date'}\n",
    "\n",
    "sbo = pd.read_csv(CSV_FILE)\n",
    "\n",
    "if 'wonum' in sbo.columns:\n",
    "    df = sbo.filter(items=list(cols.keys())).sort_values('wonum').rename(columns=cols).reset_index(drop=True)\n",
    "    df['Location'] = (df[\"Street\"] + ' FROM ' + df[\"From\"] + ' TO ' + df[\"To\"]).str.upper()\n",
    "    df.to_csv(CSV_FILE)\n",
    "else:\n",
    "    df = sbo.copy().drop(columns='Unnamed: 0').dropna(subset=['Segment IDs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will display the first 10 rows of the report from SBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Type</th>\n",
       "      <th>Finish Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Segment IDs</th>\n",
       "      <th>LongLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SG-54690</td>\n",
       "      <td>Meinardus Dr</td>\n",
       "      <td>St Elmo Rd</td>\n",
       "      <td>Sponberg Dr</td>\n",
       "      <td>Overlay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meinardus Dr FROM St Elmo Rd TO Sponberg Dr</td>\n",
       "      <td>2023206</td>\n",
       "      <td>double yellow centerline, white lane lines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location ID        Street        From           To     Type  Finish Date  \\\n",
       "0    SG-54690  Meinardus Dr  St Elmo Rd  Sponberg Dr  Overlay          NaN   \n",
       "\n",
       "                                      Location  Segment IDs  \\\n",
       "0  Meinardus Dr FROM St Elmo Rd TO Sponberg Dr      2023206   \n",
       "\n",
       "                                     LongLine  \n",
       "0  double yellow centerline, white lane lines  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(EXCEL_FILE,index_col=0)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "toc-hr-collapsed": false
   },
   "source": [
    "## Loading and Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF tables to Excel\n",
    "\n",
    "Now that the PDFs have been extracted and exported to the folder path, the next step is to extract the tables in the PDF and export it as an excel file.\n",
    "\n",
    "An input form will generate so the user can input Segment ID and comment information for each of the streets listed. The columns list will only take the relevant columns from the extracted table. The `pdfplumber` package will be used to extract tables from the PDF and prompt user to submit data.\n",
    "\n",
    "The input will be stored as a DataFrame saved to an excel document. If the user already provided input froma  previous session, the dataframe will be set to the excel file document instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Will prompt input and export to excel unless the excel file already exists. In that case it will read excel file instead\n",
    "if Path(EXCEL_FILE).exists():\n",
    "    df.to_csv(CSV_FILE)\n",
    "    df = pd.read_csv(CSV_FILE,index_col=0)\n",
    "    df = df.reset_index(drop=True).fillna(\"N/A\")\n",
    "else:\n",
    "    input_form(df)\n",
    "    df = df.fillna(\"N/A\")\n",
    "    df['LongLine'] = ['N/A' if x == '' else x for x in df['LongLine']]\n",
    "    df.to_excel(EXCEL_FILE)\n",
    "    df.to_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Street</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Type</th>\n",
       "      <th>Finish Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Segment IDs</th>\n",
       "      <th>LongLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SG-54690</td>\n",
       "      <td>Meinardus Dr</td>\n",
       "      <td>St Elmo Rd</td>\n",
       "      <td>Sponberg Dr</td>\n",
       "      <td>Overlay</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Meinardus Dr FROM St Elmo Rd TO Sponberg Dr</td>\n",
       "      <td>2023206</td>\n",
       "      <td>double yellow centerline, white lane lines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location ID        Street        From           To     Type Finish Date  \\\n",
       "0    SG-54690  Meinardus Dr  St Elmo Rd  Sponberg Dr  Overlay         N/A   \n",
       "\n",
       "                                      Location  Segment IDs  \\\n",
       "0  Meinardus Dr FROM St Elmo Rd TO Sponberg Dr      2023206   \n",
       "\n",
       "                                     LongLine  \n",
       "0  double yellow centerline, white lane lines  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a table for the list of streets with the following columns:\n",
    "- <i>Location ID</i>: unique identifier used for street paving\n",
    "- <i>Street</i>: main street that is paved\n",
    "- <i>From</i>: intersecting cross street\n",
    "- <i>To</i>: intersecting cross street\n",
    "- <i>Segment IDs</i>: list of segment IDs where street is paved seperated by commas\n",
    "- <i>Comments</i>: Notes on long line markings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Layer Data Query\n",
    "\n",
    "The next task is to find the markings through the list of segment IDs the user has inputted. For this task the `arcgis` package will be useful for extracting the markings available in each segment ID since the dataset is already available publically.\n",
    "\n",
    "Since the markings datasets are publically available, we can login to ArcGIS Online anonymously. \n",
    "\n",
    "Use `client_id` instead of `None` if you wish to log-in through an AGOL federate account. Note that it will prompt user to enter code which can be found by following the instructions. Going through an AGOL federated account is useful if the user wishes to add their own layers as a reference such as [NearMap](https://go.nearmap.com/) aerial imagery. \n",
    "\n",
    "It will search through the markings feature layer based on the list of segment IDs provided by the excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "'where' parameter is invalid\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n'where' parameter is invalid\n(Error Code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-327e27665b08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mstreets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatureLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"street_segment\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstreets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatureLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"markings_short_line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatureLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"markings_specialty_point\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d077142311ac>\u001b[0m in \u001b[0;36mquery_df\u001b[1;34m(fc, index, f, df, df1)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SEGMENT_ID IN('{})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Segment IDs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"SEGMENT_ID IN(N/A)\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_count_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0msdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\arcgis\\features\\layer.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, where, out_fields, time_filter, geometry_filter, return_geometry, return_count_only, return_ids_only, return_distinct_values, return_extent_only, group_by_fields_for_statistics, statistic_filter, result_offset, result_record_count, object_ids, distance, units, max_allowable_offset, out_sr, geometry_precision, gdb_version, order_by_fields, out_statistics, return_z, return_m, multipatch_option, quantization_parameters, return_centroid, return_all_records, result_type, historic_moment, sql_format, return_true_curves, return_exceeded_limit_features, as_df, **kwargs)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mas_df\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'returnCountOnly'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\arcgis\\features\\layer.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, url, params, raw)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[1;34m\"\"\" returns results of query \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m         result = self._con.post(path=url,\n\u001b[1;32m-> 1668\u001b[1;33m                                 postdata=params, token=self._token)\n\u001b[0m\u001b[0;32m   1669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'error'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\arcgis\\_impl\\connection.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, postdata, files, ssl, compress, is_retry, use_ordered_dict, add_token, verify_cert, token, try_json, out_folder, file_name, force_bytes, add_headers)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                                          verify_cert=verify_cert, is_retry=True)\n\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_json_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\arcgis\\_impl\\connection.py\u001b[0m in \u001b[0;36m_handle_json_error\u001b[1;34m(self, error, errorcode)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[0merrormessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrormessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n(Error Code: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrorcode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\")\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrormessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_StrictURLopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFancyURLopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n'where' parameter is invalid\n(Error Code: 400)"
     ]
    }
   ],
   "source": [
    "# variables used to find and query feature layer in AGOL\n",
    "gis = GIS(\"https://austin.maps.arcgis.com/home/index.html\")\n",
    "url = r\"https://services.arcgis.com/0L95CJ0VTaxqcmED/arcgis/rest/services/TRANSPORTATION_{}/FeatureServer/0\"\n",
    "sl,sp,streets = (pd.DataFrame(),pd.DataFrame(),pd.DataFrame())\n",
    "\n",
    "# Columns for data frame. Indexes: df (0), shortline (1-4), specialty point (3 to etc.)\n",
    "cols = ['SHORT_LINE_TYPE','SEGMENT_ID','SPECIALTY_POINT_TYPE','SPECIALTY_POINT_SUB_TYPE']\n",
    "s_col = ['LEFT_BLOCK_FROM','RIGHT_BLOCK_FROM','SEGMENT_ID']\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    streets = query_df(FeatureLayer(url.format(\"street_segment\")),index,s_col,df,streets)      \n",
    "    sl = query_df(FeatureLayer(url.format(\"markings_short_line\")),index,cols[:2],df,sl)\n",
    "    sp = query_df(FeatureLayer(url.format(\"markings_specialty_point\")),index,cols[1:],df,sp)\n",
    "sp = FeatureLayerDataFrame('markings_specialty_point').specialty_markings(sp)\n",
    "\n",
    "# Order table\n",
    "streets['BLOCK'] = np.maximum(streets[s_col[0]],streets[s_col[1]])\n",
    "streets = streets.sort_values(by=['BLOCK','Location ID']).reset_index(drop = True)\n",
    "streets = streets.rename(columns={'COUNTS':'PAGE'}).drop(s_col[:2],axis=1)\n",
    "\n",
    "page = 1\n",
    "for index, row in streets.iterrows():\n",
    "    if index != 0 and (row['Location ID'] != streets['Location ID'][index - 1]):\n",
    "        page = 2\n",
    "        streets.at[index,'PAGE'] = page\n",
    "    else:\n",
    "        page += 1\n",
    "        streets.at[index,'PAGE'] = page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Plans Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sl_page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b006abe7fa74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sl_page' is not defined"
     ]
    }
   ],
   "source": [
    "display(sl_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cover Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SHORT_LINE_TYPE</th>\n",
       "      <th>Location ID</th>\n",
       "      <th>CROSSWALK</th>\n",
       "      <th>STOP_LINE</th>\n",
       "      <th>SHORT LINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SG-54661</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SHORT LINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SHORT_LINE_TYPE Location ID  CROSSWALK  STOP_LINE  SHORT LINE\n",
       "0                  SG-54661          2          2  SHORT LINE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SPECIALTY MARKINGS', 'SHORT LINE'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-ad8c1236a1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#sp_count, sp_page = location_in_df(sp,'SPECIALTY_POINT_TYPE',wg[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_cover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msl_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msl_page\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d077142311ac>\u001b[0m in \u001b[0;36mcreate_cover\u001b[1;34m(cover, sl_count, sp_count, wg)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcover\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'N/A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mcover\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'WORK GROUPS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcover\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'N/A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcover\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'N/A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecifications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SPECIALTY MARKINGS', 'SHORT LINE'] not in index\""
     ]
    }
   ],
   "source": [
    "wg = ['SHORT LINE','SPECIALTY MARKINGS','LONGLINE']\n",
    "sl_count,sl_page = location_in_df(sl,'SHORT_LINE_TYPE',wg[0])\n",
    "display(sl_count)\n",
    "#sp_count, sp_page = location_in_df(sp,'SPECIALTY_POINT_TYPE',wg[1])\n",
    "cover = create_cover(df.copy(),sl_count,sp_count,wg)\n",
    "pages = create_pages(df.copy(),sl_page,sp_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cover Table\n",
    "This dataframe lists pavement markings queried by segment IDs with the following columns:\n",
    "- <i>Location ID</i>: Unique identifier used for street paving\n",
    "- <i>Location</i>: Location of wherreabouts work\n",
    "- <i>WORK GROUPS</i>: Type of markings work group assigned to work order\n",
    "- <i>SPECIFICATIONS</i>: Lists all markings that need to be installed on work order.\n",
    "\n",
    "The dataframe will be saves in an excel sheet for it to be used again to generate the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>WORK GROUPS</th>\n",
       "      <th>SPECIFICATIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>70194</td>\n",
       "      <td>Rainey St FROM Cummings St TO Driskill St</td>\n",
       "      <td>['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']</td>\n",
       "      <td>Install 1 yield line, 3 parking 'l'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>79816</td>\n",
       "      <td>River St FROM Red River St TO East Ave</td>\n",
       "      <td>['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']</td>\n",
       "      <td>Install 1 crosswalk, 2 parking 'l' , 2 parking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SG-98745935</td>\n",
       "      <td>Radam Ln FROM S 1st St TO James Casey</td>\n",
       "      <td>['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']</td>\n",
       "      <td>Install partial double yellow centerline, turn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location ID                                   Location  \\\n",
       "0        70194  Rainey St FROM Cummings St TO Driskill St   \n",
       "1        79816     River St FROM Red River St TO East Ave   \n",
       "2  SG-98745935      Radam Ln FROM S 1st St TO James Casey   \n",
       "\n",
       "                                        WORK GROUPS  \\\n",
       "0  ['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']   \n",
       "1  ['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']   \n",
       "2  ['SHORT LINE', 'SPECIALTY MARKINGS', 'LONGLINE']   \n",
       "\n",
       "                                      SPECIFICATIONS  \n",
       "0               Install 1 yield line, 3 parking 'l'   \n",
       "1  Install 1 crosswalk, 2 parking 'l' , 2 parking...  \n",
       "2  Install partial double yellow centerline, turn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cover.filter(['Location ID','Location','Comments','WORK GROUPS','SPECIFICATIONS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pages Table\n",
    "This dataframe lists pavement markings queried by segment IDs with the following columns:\n",
    "- <i>LOCATION ID</i>: Unique identifier used for street paving\n",
    "- <i>SEGMENT_ID</i>: Segment ID of page reference\n",
    "- <i>SPECIFICATIONS</i>: Lists all markings that need to be installed on work order.\n",
    "- <i>PAGE</i>: Page number used for work order\n",
    "\n",
    "The dataframe will be saves in an excel sheet for it to be used again to generate the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location ID</th>\n",
       "      <th>SEGMENT_ID</th>\n",
       "      <th>SPECIFICATIONS</th>\n",
       "      <th>PAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>70194</td>\n",
       "      <td>2019466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>79816</td>\n",
       "      <td>2019341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>79816</td>\n",
       "      <td>2019355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>79816</td>\n",
       "      <td>2019370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SG-98745935</td>\n",
       "      <td>2024315</td>\n",
       "      <td>Install partial double yellow centerline, turn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location ID  SEGMENT_ID                                     SPECIFICATIONS  \\\n",
       "0        70194     2019466                                                NaN   \n",
       "1        79816     2019341                                                NaN   \n",
       "2        79816     2019355                                                NaN   \n",
       "3        79816     2019370                                                NaN   \n",
       "4  SG-98745935     2024315  Install partial double yellow centerline, turn...   \n",
       "\n",
       "   PAGE  \n",
       "0     2  \n",
       "1     2  \n",
       "2     2  \n",
       "3     3  \n",
       "4     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pages.filter(['Location ID','SEGMENT_ID','SPECIFICATIONS','PAGE'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Worksheets of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(filename = EXCEL_FILE)\n",
    "create_ws(cover,'Cover')\n",
    "create_ws(pages,'Pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Whereabouts Plans\n",
    "To generate whereabout plans, we will have to use the `arcpy` package, which requires Python 2 and ArcMap 10.5. Eventually, this notebook will be able to use `arcpy` in Python 3.\n",
    "\n",
    "[Click here to access notebook](PlansTemplate.ipynb)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
